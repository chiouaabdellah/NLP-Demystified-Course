{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Demystified | Preprocessing: Case_folding, Stop words Removal, Stemming, Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (57.4.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\chiou\\OneDrive\\Bureau\\Projects_CDL\\NLP demystified\\NLPdymenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"He told Dr. Lovato that he was done with the tests and would post the results shortly.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-Folding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ for t in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[He, 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'tests', 'and', 'would', 'post', 'the', 'results', 'shortly', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ if not t.is_sent_start else t for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'becomes', 'yourself', 'already', 'among', 'though', 'thereby', 'whose', 'whereby', 'anyway', 'whether', 're', 'eleven', 'quite', 'still', 'are', '’s', 'doing', 'although', 'any', 'through', 'ten', 'once', 'or', 'serious', 'latterly', 'seeming', 'over', 'i', 'say', 'third', 'these', 'next', 'otherwise', 'it', 'would', 'such', 'his', 'several', 'within', 'out', 'made', 'thus', 'not', 'our', \"'m\", '’ll', 'nobody', 'whereas', \"'ll\", 'go', 'same', 'because', 'six', 'up', 'hers', 'nine', 'them', 'moreover', 'to', 'her', 'thereafter', 'myself', 'whatever', 'itself', 'its', 'so', 'also', 'really', 'seems', 'where', '‘re', 'indeed', 'whence', 'twenty', 'he', 'must', 'were', 'has', 'something', 'toward', 'during', 'an', '’d', 'twelve', 'ours', 'than', 'everywhere', 'beforehand', 'via', 'noone', 'anyhow', 'anything', 'never', \"'s\", '’re', 'alone', 'upon', 'less', 'give', '’ve', 'n’t', 'ourselves', 'now', 'regarding', 'onto', 'do', 'fifty', 'under', 'your', \"n't\", 'thereupon', 'somewhere', 'bottom', 'should', 'into', 'between', 'see', 'full', 'many', 'throughout', 'n‘t', 'very', 'side', 'without', 'there', 'top', '‘ve', \"'d\", 'might', 'who', 'did', 'a', 'ca', 'about', 'why', \"'ve\", 'above', 'beyond', 'became', 'call', 'someone', 'herein', '‘d', 'whole', 'had', 'using', 'along', 'whenever', 'have', 'nevertheless', 'in', 'and', 'mine', 'they', 'various', 'that', 'she', 'four', 'yet', 'sometimes', 'will', 'but', 'own', 'whereafter', 'eight', 'well', 'least', 'how', 'wherein', 'make', 'amongst', 'you', 'put', 'whereupon', 'for', 'amount', 'one', 'forty', 'which', 'off', 'whom', 'keep', 'neither', 'be', 'whither', 'yours', 'here', 'everything', 'afterwards', '‘ll', 'please', 'with', 'whoever', 'only', 'been', 'hundred', 'more', 'further', 'herself', 'was', 'two', 'becoming', 'former', 'after', 'thence', 'done', 'fifteen', 'latter', 'others', 'besides', 'being', 'due', 'none', 'while', 'since', 'therein', 'seem', 'my', 'even', 'we', 'another', 'too', 'except', '’m', 'then', 'just', 'move', 'may', 'together', 'other', 'as', 'of', 'get', 'could', 'nor', 'down', 'hereafter', 'against', 'their', 'most', 'ever', 'per', 'empty', 'on', 'five', 'almost', 'this', 'what', 'namely', 'him', 'however', 'formerly', 'three', 'hereupon', 'part', 'somehow', 'some', 'before', 'front', 'until', 'anyone', 'last', 'back', 'around', 'enough', 'all', 'perhaps', \"'re\", 'is', 'hereby', 'else', 'wherever', 'become', 'from', 'sometime', '‘m', 'those', 'first', 'across', 'nothing', 'themselves', 'mostly', 'hence', 'used', 'seemed', 'us', 'sixty', 'behind', 'meanwhile', 'below', 'does', 'if', 'take', 'towards', 'unless', '‘s', 'cannot', 'name', 'always', 'can', 'himself', 'am', 'thru', 'both', 'elsewhere', 'either', 'yourselves', 'by', 'me', 'often', 'show', 'nowhere', 'anywhere', 'few', 'much', 'the', 'beside', 'when', 'each', 'again', 'rather', 'everyone', 'therefore', 'no', 'every', 'at'}\n"
     ]
    }
   ],
   "source": [
    "print(nlp.Defaults.stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326\n"
     ]
    }
   ],
   "source": [
    "print(len(nlp.Defaults.stop_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[told, Dr., Lovato, tests, post, results, shortly, .]\n"
     ]
    }
   ],
   "source": [
    "print([t.lower_ if not t.sent_start else t for t in doc if not t.is_stop ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmetization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 'he'), ('told', 'tell'), ('Dr.', 'Dr.'), ('Lovato', 'Lovato'), ('that', 'that'), ('he', 'he'), ('was', 'be'), ('done', 'do'), ('with', 'with'), ('the', 'the'), ('tests', 'test'), ('and', 'and'), ('would', 'would'), ('post', 'post'), ('the', 'the'), ('results', 'result'), ('shortly', 'shortly'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print([(t.text, t.lemma_) for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['he', 'told', 'dr.', 'lovato', 'that', 'he', 'was', 'done', 'with', 'the', 'test', 'and', 'would', 'post', 'the', 'result', 'short', '.']\n"
     ]
    }
   ],
   "source": [
    "# EXERCISE: Find out how to intialize the SnowballStemmer, then tokenize and stem the sentence below.\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "s = 'He told Dr. Lovato that he was done with the tests and would post the results shortly.'\n",
    "\n",
    "# Initialize the stemmer here.\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Tokenize, stem, and print the tokens.\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "doc = tokenizer.tokenize(s)\n",
    "stemmed_tokens = [stemmer.stem(token)  for token in doc]\n",
    "print(stemmed_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'becomes', 'yourself', 'already', 'among', 'though', 'thereby', 'whose', 'whereby', 'anyway', 'whether', 're', 'eleven', 'quite', 'still', 'are', '’s', 'doing', 'although', 'any', 'through', 'ten', 'once', 'or', 'serious', 'latterly', 'seeming', 'over', 'i', 'say', 'third', 'these', 'next', 'otherwise', 'it', 'would', 'such', 'his', 'several', 'within', 'out', 'made', 'thus', 'not', 'our', \"'m\", '’ll', 'nobody', 'whereas', \"'ll\", 'go', 'same', 'because', 'six', 'up', 'hers', 'told', 'nine', 'them', 'moreover', 'to', 'her', 'thereafter', 'myself', 'whatever', 'itself', 'its', 'so', 'also', 'really', 'seems', 'where', '‘re', 'indeed', 'whence', 'twenty', 'he', 'must', 'were', 'has', 'something', 'toward', 'during', 'an', '’d', 'twelve', 'ours', 'than', 'everywhere', 'beforehand', 'via', 'noone', 'anyhow', 'anything', 'never', \"'s\", '’re', 'alone', 'upon', 'less', 'give', '’ve', 'n’t', 'ourselves', 'now', 'regarding', 'onto', 'do', 'fifty', 'under', 'your', \"n't\", 'thereupon', 'somewhere', 'bottom', 'should', 'into', 'between', 'see', 'full', 'many', 'throughout', 'n‘t', 'very', 'side', 'without', 'there', 'top', '‘ve', \"'d\", 'might', 'who', 'did', 'a', 'ca', 'about', 'why', \"'ve\", 'above', 'beyond', 'became', 'call', 'someone', 'herein', '‘d', 'whole', 'had', 'using', 'along', 'whenever', 'have', 'nevertheless', 'in', 'and', 'mine', 'they', 'various', 'that', 'she', 'four', 'yet', 'sometimes', 'will', 'but', 'own', 'whereafter', 'eight', 'well', 'least', 'how', 'wherein', 'make', 'amongst', 'you', 'put', 'whereupon', 'for', 'amount', 'one', 'forty', 'which', 'off', 'whom', 'keep', 'neither', 'be', 'whither', 'yours', 'here', 'everything', 'afterwards', '‘ll', 'please', 'with', 'whoever', 'only', 'been', 'hundred', 'more', 'further', 'herself', 'was', 'two', 'becoming', 'former', 'after', 'thence', 'done', 'fifteen', 'latter', 'others', 'besides', 'being', 'due', 'none', 'while', 'since', 'therein', 'seem', 'my', 'even', 'we', 'another', 'too', 'except', '’m', 'then', 'just', 'move', 'may', 'together', 'other', 'as', 'of', 'get', 'could', 'nor', 'down', 'hereafter', 'against', 'their', 'most', 'ever', 'per', 'empty', 'on', 'five', 'almost', 'this', 'what', 'namely', 'him', 'however', 'formerly', 'three', 'hereupon', 'part', 'somehow', 'some', 'before', 'front', 'until', 'anyone', 'last', 'back', 'around', 'enough', 'all', 'perhaps', \"'re\", 'is', 'hereby', 'else', 'wherever', 'become', 'from', 'sometime', '‘m', 'those', 'first', 'across', 'nothing', 'themselves', 'mostly', 'hence', 'used', 'seemed', 'us', 'sixty', 'behind', 'meanwhile', 'below', 'does', 'if', 'take', 'towards', 'unless', '‘s', 'cannot', 'name', 'always', 'can', 'himself', 'am', 'thru', 'both', 'elsewhere', 'either', 'yourselves', 'by', 'me', 'often', 'show', 'nowhere', 'anywhere', 'few', 'much', 'the', 'beside', 'when', 'each', 'again', 'rather', 'everyone', 'therefore', 'no', 'every', 'at'}\n",
      "327\n"
     ]
    }
   ],
   "source": [
    "## Adding custom stop words : \n",
    "\n",
    "# EXERCISE: Find out how to add and remove your own stop words in spaCy. Add the \n",
    "# word 'told' as a stop word, test that it works, then remove it from \n",
    "# the stop word list.\n",
    "\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "STOP_WORDS.add('told')\n",
    "print(STOP_WORDS)\n",
    "print(len(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[needed, glitter, old, lame, meme]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "s = \"I told you we needed more glitter very old lame meme\"\n",
    "doc = nlp(s)\n",
    "print([t  for t in doc if not t.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'becomes', 'yourself', 'already', 'among', 'though', 'thereby', 'whose', 'whereby', 'anyway', 'whether', 're', 'eleven', 'quite', 'still', 'are', '’s', 'doing', 'although', 'any', 'through', 'ten', 'once', 'or', 'serious', 'latterly', 'seeming', 'over', 'i', 'say', 'third', 'these', 'next', 'otherwise', 'it', 'would', 'such', 'his', 'several', 'within', 'out', 'made', 'thus', 'not', 'our', \"'m\", '’ll', 'nobody', 'whereas', \"'ll\", 'go', 'same', 'because', 'six', 'up', 'hers', 'nine', 'them', 'moreover', 'to', 'her', 'thereafter', 'myself', 'whatever', 'itself', 'its', 'so', 'also', 'really', 'seems', 'where', '‘re', 'indeed', 'whence', 'twenty', 'he', 'must', 'were', 'has', 'something', 'toward', 'during', 'an', '’d', 'twelve', 'ours', 'than', 'everywhere', 'beforehand', 'via', 'noone', 'anyhow', 'anything', 'never', \"'s\", '’re', 'alone', 'upon', 'less', 'give', '’ve', 'n’t', 'ourselves', 'now', 'regarding', 'onto', 'do', 'fifty', 'under', 'your', \"n't\", 'thereupon', 'somewhere', 'bottom', 'should', 'into', 'between', 'see', 'full', 'many', 'throughout', 'n‘t', 'very', 'side', 'without', 'there', 'top', '‘ve', \"'d\", 'might', 'who', 'did', 'a', 'ca', 'about', 'why', \"'ve\", 'above', 'beyond', 'became', 'call', 'someone', 'herein', '‘d', 'whole', 'had', 'using', 'along', 'whenever', 'have', 'nevertheless', 'in', 'and', 'mine', 'they', 'various', 'that', 'she', 'four', 'yet', 'sometimes', 'will', 'but', 'own', 'whereafter', 'eight', 'well', 'least', 'how', 'wherein', 'make', 'amongst', 'you', 'put', 'whereupon', 'for', 'amount', 'one', 'forty', 'which', 'off', 'whom', 'keep', 'neither', 'be', 'whither', 'yours', 'here', 'everything', 'afterwards', '‘ll', 'please', 'with', 'whoever', 'only', 'been', 'hundred', 'more', 'further', 'herself', 'was', 'two', 'becoming', 'former', 'after', 'thence', 'done', 'fifteen', 'latter', 'others', 'besides', 'being', 'due', 'none', 'while', 'since', 'therein', 'seem', 'my', 'even', 'we', 'another', 'too', 'except', '’m', 'then', 'just', 'move', 'may', 'together', 'other', 'as', 'of', 'get', 'could', 'nor', 'down', 'hereafter', 'against', 'their', 'most', 'ever', 'per', 'empty', 'on', 'five', 'almost', 'this', 'what', 'namely', 'him', 'however', 'formerly', 'three', 'hereupon', 'part', 'somehow', 'some', 'before', 'front', 'until', 'anyone', 'last', 'back', 'around', 'enough', 'all', 'perhaps', \"'re\", 'is', 'hereby', 'else', 'wherever', 'become', 'from', 'sometime', '‘m', 'those', 'first', 'across', 'nothing', 'themselves', 'mostly', 'hence', 'used', 'seemed', 'us', 'sixty', 'behind', 'meanwhile', 'below', 'does', 'if', 'take', 'towards', 'unless', '‘s', 'cannot', 'name', 'always', 'can', 'himself', 'am', 'thru', 'both', 'elsewhere', 'either', 'yourselves', 'by', 'me', 'often', 'show', 'nowhere', 'anywhere', 'few', 'much', 'the', 'beside', 'when', 'each', 'again', 'rather', 'everyone', 'therefore', 'no', 'every', 'at'}\n",
      "326\n"
     ]
    }
   ],
   "source": [
    "STOP_WORDS.remove('told')\n",
    "print(STOP_WORDS)\n",
    "print(len(STOP_WORDS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[told, needed, glitter, old, lame, meme]\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "s = \"I told you we needed more glitter very old lame meme\"\n",
    "doc = nlp(s)\n",
    "print([t  for t in doc if not t.is_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPdymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
