{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Demystified | Preprocessing: Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (57.4.0)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\chiou\\onedrive\\bureau\\projects_cdl\\nlp demystified\\nlpdymenv\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\chiou\\OneDrive\\Bureau\\Projects_CDL\\NLP demystified\\NLPdymenv\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing a simple string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['He', 'did', \"n't\", 'want', 'to', 'pay', '$', '20', 'for', 'this', 'book', '.']\n"
     ]
    }
   ],
   "source": [
    "print([t.text for t in doc ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n"
     ]
    }
   ],
   "source": [
    "print(doc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.token.Token'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc[0])) #Token object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "print(type(doc[1:4])) #span object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('He', 0), ('did', 1), (\"n't\", 2), ('want', 3), ('to', 4), ('pay', 5), ('$', 6), ('20', 7), ('for', 8), ('this', 9), ('book', 10), ('.', 11)]\n"
     ]
    }
   ],
   "source": [
    "print([(t.text, t.i) for t in doc ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He didn't want to pay $20 for this book.\n"
     ]
    }
   ],
   "source": [
    "# Spacy does non destructive Tokenization which means the input is always retreivable after Tokenization \n",
    "print(doc.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Either the well was very deep, or she fell very slowly, for she \n",
      "had plenty of time as she went down to look about her and to wonder what \n",
      "was going to happen next., First, she tried to look down and make out what \n",
      "she was coming to, but it was too dark to see anything; then she looked at \n",
      "the sides of the well, and noticed that they were filled with cupboards and \n",
      "book-shelves; here and there she saw maps and pictures hung upon pegs.]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization of a full text \n",
    "\n",
    "s = \"\"\"Either the well was very deep, or she fell very slowly, for she \n",
    "had plenty of time as she went down to look about her and to wonder what \n",
    "was going to happen next. First, she tried to look down and make out what \n",
    "she was coming to, but it was too dark to see anything; then she looked at \n",
    "the sides of the well, and noticed that they were filled with cupboards and \n",
    "book-shelves; here and there she saw maps and pictures hung upon pegs.\"\"\"\n",
    "\n",
    "doc = nlp(s)\n",
    "\n",
    "print([sent for sent in doc.sents])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$20\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# EXERCISE:\n",
    "# 1) Tokenize the following text\n",
    "# 2) Iterate through the tokens to check whether there's a currency symbol.\n",
    "# 3) If there is, and the currency label is followed by a number, print\n",
    "#    both the symbol and the number.\n",
    "# \n",
    "# Look through https://spacy.io/api/token#attributes on how to check whether\n",
    "# a token is a currency symbol or a number.\n",
    "#\n",
    "# Expected output: \"$20\".\n",
    "s = \"He didn't want to pay $20 for this book.\"\n",
    "doc = nlp(s)\n",
    "for token in doc: \n",
    "    if token.like_num:\n",
    "        token_list = [(t.text, t.i) for t in doc]\n",
    "        for j in range(len(token_list)):\n",
    "            if token_list[j][1] == token.i -1:\n",
    "                prev_token = token_list[j][0]\n",
    "        print(str(prev_token) + str(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Let', \"'s\", 'go', 'to', 'N.Y.C.', 'for', 'the', 'weekend', '.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "s = \"Let's go to N.Y.C. for the weekend.\"\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "tokenizer.tokenize(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLPdymenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
